Create S3 buckets for url files, raw data, and cleaned data

Create lambdas:
url-search
Memory: 256MB
Timeout: 20s
environment variables:
s3_target_bucket

extract-data
Memory: 256MB
Timeout: 20s
environment variables:
s3_target_bucket
trigger:
S3:[url-search s3 target]:put objects

transform lambda function
Memory: 4000MB
Timeout: 50s
environment variables:
missing_field_default_value
s3_target_bucket
trigger: 
S3:[extract-data s3 target]:put objects

load

add environment variables to lambdas

add triggers to lambdas

upload deployment packages for each lambda

update handler with name of python file

update runtime and memory as needed

Example: https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html


ElasticSearch setup

Create domain

Add domain(host) to load lambda

After data pipeline is run (documents are indexed) then create index pattern in Kibana
